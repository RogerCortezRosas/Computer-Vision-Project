{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YeXWWW_PMx8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 Desinstalar posibles versiones conflictivas\n",
        "!pip uninstall -y tensorflow keras protobuf\n",
        "\n",
        "# 📌 Instalar versiones compatibles\n",
        "!pip install tensorflow==2.12.0 keras==2.12.0 protobuf==3.20.3\n"
      ],
      "metadata": {
        "id": "kbUr4ROADAgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 📌 Instalar dependencias de la API\n",
        "!pip install tf_slim pycocotools contextlib2 pillow lxml matplotlib pandas opencv-python-headless Cython tensorflow_io apache-beam\n",
        "\n",
        "# 📌 Instalar compilador protobuf\n",
        "!apt-get install -y protobuf-compiler\n",
        "\n",
        "# 📌 Clonar repositorio oficial\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# 📌 Compilar archivos .proto\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# 📌 Instalar la API sin actualizar dependencias\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install . --no-deps\n",
        "\n",
        "# 📌 Exportar PYTHONPATH\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models:/content/models/research:/content/models/research/slim'\n",
        "\n",
        "# 📌 Verificar instalación\n",
        "!python object_detection/builders/model_builder_tf2_test.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml1trW6VM6UK",
        "outputId": "74f5ad1f-7012-40bc-9fc6-3053b501c169"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.11/dist-packages (21.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.11/dist-packages (0.37.1)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.11/dist-packages (2.65.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf_slim) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_io) (0.37.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (3.10.18)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.3.1.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (1.11.1)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (1.65.5)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (3.4.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.7.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (4.13.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (5.3.0)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (2024.11.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (2.32.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (4.13.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (6.0.2)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.11/dist-packages (from apache-beam) (0.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (0.6.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.17.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.24.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam) (2.7.0)\n",
            "Requirement already satisfied: PyJWT~=2.9.0 in /usr/local/lib/python3.11/dist-packages (from redis<6,>=5.0.0->apache-beam) (2.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2025.4.26)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 93 not upgraded.\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: object_detection\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697324 sha256=5d57ef91e4ac610b69e433c4b0cbde6633b177f2448a84ea4788c127409d983d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t9cddo1i/wheels/95/4a/63/b2d36ca06eab841de19a38993ffaf2beac152a44539bc642a6\n",
            "Successfully built object_detection\n",
            "Installing collected packages: object_detection\n",
            "  Attempting uninstall: object_detection\n",
            "    Found existing installation: object_detection 0.1\n",
            "    Uninstalling object_detection-0.1:\n",
            "      Successfully uninstalled object_detection-0.1\n",
            "Successfully installed object_detection-0.1\n",
            "2025-05-24 02:10:44.019417: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-24 02:10:44.084956: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-05-24 02:10:44.085466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-24 02:10:45.678624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 70, in <module>\n",
            "    from object_detection.models import ssd_efficientnet_bifpn_feature_extractor as ssd_efficientnet_bifpn\n",
            "  File \"/content/models/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py\", line 35, in <module>\n",
            "    from official.legacy.image_classification.efficientnet import efficientnet_model\n",
            "  File \"/content/models/official/legacy/image_classification/efficientnet/efficientnet_model.py\", line 30, in <module>\n",
            "    import tensorflow as tf, tf_keras\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__init__.py\", line 3, in <module>\n",
            "    from tf_keras import __internal__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/__init__.py\", line 3, in <module>\n",
            "    from tf_keras.__internal__ import backend\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/backend/__init__.py\", line 3, in <module>\n",
            "    from tf_keras.src.backend import _initialize_variables as initialize_variables\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/__init__.py\", line 21, in <module>\n",
            "    from tf_keras.src import applications\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/__init__.py\", line 18, in <module>\n",
            "    from tf_keras.src.applications.convnext import ConvNeXtBase\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/convnext.py\", line 28, in <module>\n",
            "    from tf_keras.src import backend\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/backend.py\", line 35, in <module>\n",
            "    from tf_keras.src.engine import keras_tensor\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/keras_tensor.py\", line 19, in <module>\n",
            "    from tf_keras.src.utils import object_identity\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/__init__.py\", line 53, in <module>\n",
            "    from tf_keras.src.utils.feature_space import FeatureSpace\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/feature_space.py\", line 20, in <module>\n",
            "    from tf_keras.src.engine import base_layer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/base_layer.py\", line 35, in <module>\n",
            "    from tf_keras.src.dtensor import lazy_variable\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/dtensor/lazy_variable.py\", line 23, in <module>\n",
            "    from tensorflow.python.framework import tensor\n",
            "ImportError: cannot import name 'tensor' from 'tensorflow.python.framework' (/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show protobuf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q32u6TaMDOZn",
        "outputId": "ca59d1e8-0e30-4f8b-ed2d-f59f759454da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: protobuf\n",
            "Version: 3.20.3\n",
            "Summary: Protocol Buffers\n",
            "Home-page: https://developers.google.com/protocol-buffers/\n",
            "Author: \n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: apache-beam, google-ai-generativelanguage, google-api-core, google-cloud-aiplatform, google-cloud-bigquery-connection, google-cloud-bigquery-storage, google-cloud-dataproc, google-cloud-datastore, google-cloud-firestore, google-cloud-functions, google-cloud-iam, google-cloud-language, google-cloud-resource-manager, google-cloud-spanner, google-cloud-translate, google-generativeai, googleapis-common-protos, grpc-google-iam-v1, grpcio-status, kaggle, orbax-checkpoint, proto-plus, tb-nightly, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-metadata, tf-hub-nightly, tf_nightly, wandb, ydf, yfinance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'carro', 'id': 1}, {'name': 'motos', 'id': 2}]\n",
        "with open(\"label_map.pbtxt\", \"w\") as f:\n",
        "  for label in labels:\n",
        "    f.write('item { \\n')\n",
        "    f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "    f.write('\\tid:{}\\n'.format(label['id']))\n",
        "    f.write('}\\n')"
      ],
      "metadata": {
        "id": "ZEFyE79IRzre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descargar los modelos pre-entrenados en este caso SSD + MobileNetV2\n",
        "!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz \\\n",
        "-O /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su0UOs1VQ4b-",
        "outputId": "c12d82b7-bc34-439a-8001-4f80538ebc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-23 23:46:55--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.24.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.24.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "/content/ssd_mobile 100%[===================>]  19.56M  9.46MB/s    in 2.1s    \n",
            "\n",
            "2025-05-23 23:46:57 (9.46 MB/s) - ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# descomprimir el archivo .gz\n",
        "#!tar -zxvf /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "output_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print(\"La carpeta se almaceno en {}\".format(output_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMCwndO1R42e",
        "outputId": "3a275490-7c39-4f16-9519-a16fea5773f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La carpeta se almaceno en /content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# crear carpeta de entrenamineto\n",
        "path_training = '/content/ssd_mobilenet'\n",
        "#os.mkdir(path_training)"
      ],
      "metadata": {
        "id": "1O5LTGFVS4jX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mover el archivo pipeline.config de la carpeta ssd_mobilenet_v2.... hacia la carpeta ssd_mobilenet\n",
        "shutil.move('/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config', path_training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "kIrMyE_rTJu8",
        "outputId": "90b6e288-31be-4ecc-85c5-70bf750dfc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "Destination path '/content/ssd_mobilenet/pipeline.config' already exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c304402ecc0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mover el archivo pipeline.config de la carpeta ssd_mobilenet_v2.... hacia la carpeta ssd_mobilenet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Destination path '/content/ssd_mobilenet/pipeline.config' already exists"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "UTmeZgvPTJpD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.protos import pipeline_pb2\n"
      ],
      "metadata": {
        "id": "tsm9CpEl4Ref"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crear el archivo de configuracio para que lo podamos editar\n",
        "\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(os.path.join(path_training, 'pipeline.config'), 'r') as f:\n",
        "  proto_str = f.read()\n",
        "  # Remove the problematic field before parsing\n",
        "  proto_str = proto_str.replace('fine_tune_checkpoint_version: V2', '')\n",
        "  text_format.Merge(proto_str, pipeline)"
      ],
      "metadata": {
        "id": "0qBITrfrTJla"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_map_path = '/content/label_map.pbtxt'\n",
        "train_record_path = '/content/train.record'\n",
        "test_record_path = '/content/test.record'"
      ],
      "metadata": {
        "id": "nxtfBZlCaCxY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Editar el archivo config de la arquitectura de mobilenet_v2\n",
        "\n",
        "# Establecer el numero de clases\n",
        "pipeline.model.ssd.num_classes = 2\n",
        "\n",
        "# Establecer la cantidad del lote\n",
        "pipeline.train_config.batch_size = 4\n",
        "\n",
        "# Definimos desde donde quiero que empieze a entrenar , desde que checkpoint\n",
        "pipeline.train_config.fine_tune_checkpoint = os.path.join(output_path, 'checkpoint/ckpt-0')\n",
        "\n",
        "# Definir que tipo de entrenamiento queremos hacer\n",
        "pipeline.train_config.fine_tune_checkpoint_type = 'detection'\n",
        "\n",
        "\n",
        "#Obtener el path del label_map de train\n",
        "pipeline.train_input_reader.label_map_path = label_map_path\n",
        "\n",
        "#Leer el archivo tf record train\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[0] = train_record_path\n",
        "\n",
        "# Obtener el path del label_map de test\n",
        "pipeline.eval_input_reader[0].label_map_path = label_map_path\n",
        "\n",
        "#Leer el archivo tf record test\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZP4O3dt6TJiq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sobre escribimos el arvhio pipeline en el archivo pipeline.config dentro de la carpeta ssd_mobilenet\n",
        "config_text = text_format.MessageToString(pipeline)\n",
        "with tf.io.gfile.GFile(os.path.join(path_training, 'pipeline.config'), 'wb') as f:\n",
        "  f.write(config_text)"
      ],
      "metadata": {
        "id": "UIPE35msTJep"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "#Definicion de parametros\n",
        "\n",
        "num_steps = 5000\n",
        "num_eval_steps = 500\n",
        "model_dir = '/content/ssd_mobilenet'\n",
        "\n",
        "# Script de tensorflow  para entrener el modelo con la API DE Open detection\n",
        "\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "--pipeline_config_path={path_training}/pipeline.config \\\n",
        "--num_train_steps={num_steps} \\\n",
        "--model_dir={model_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUxnNgQiTJYL",
        "outputId": "9a131516-29dc-483e-e5df-700a906ffb65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-24 02:05:58.895871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 31, in <module>\n",
            "    from object_detection import model_lib_v2\n",
            "  File \"/content/models/research/object_detection/model_lib_v2.py\", line 30, in <module>\n",
            "    from object_detection import inputs\n",
            "  File \"/content/models/research/object_detection/inputs.py\", line 27, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 70, in <module>\n",
            "    from object_detection.models import ssd_efficientnet_bifpn_feature_extractor as ssd_efficientnet_bifpn\n",
            "  File \"/content/models/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py\", line 35, in <module>\n",
            "    from official.legacy.image_classification.efficientnet import efficientnet_model\n",
            "  File \"/content/models/official/legacy/image_classification/efficientnet/efficientnet_model.py\", line 30, in <module>\n",
            "    import tensorflow as tf, tf_keras\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__init__.py\", line 3, in <module>\n",
            "    from tf_keras import __internal__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/__init__.py\", line 3, in <module>\n",
            "    from tf_keras.__internal__ import backend\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/__internal__/backend/__init__.py\", line 3, in <module>\n",
            "    from tf_keras.src.backend import _initialize_variables as initialize_variables\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/__init__.py\", line 21, in <module>\n",
            "    from tf_keras.src import applications\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/__init__.py\", line 18, in <module>\n",
            "    from tf_keras.src.applications.convnext import ConvNeXtBase\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/applications/convnext.py\", line 28, in <module>\n",
            "    from tf_keras.src import backend\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/backend.py\", line 35, in <module>\n",
            "    from tf_keras.src.engine import keras_tensor\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/keras_tensor.py\", line 19, in <module>\n",
            "    from tf_keras.src.utils import object_identity\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/__init__.py\", line 53, in <module>\n",
            "    from tf_keras.src.utils.feature_space import FeatureSpace\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/feature_space.py\", line 20, in <module>\n",
            "    from tf_keras.src.engine import base_layer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/base_layer.py\", line 35, in <module>\n",
            "    from tf_keras.src.dtensor import lazy_variable\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/dtensor/lazy_variable.py\", line 23, in <module>\n",
            "    from tensorflow.python.framework import tensor\n",
            "ImportError: cannot import name 'tensor' from 'tensorflow.python.framework' (/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow"
      ],
      "metadata": {
        "id": "dMqeNrACTJVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a847455b-f9b5-4993-ceb0-24cb89191b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.18.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf-models-official, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIdle54STJST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUhsF2Y1TJOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MJ7HqfhTJKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "a9b9c084",
        "outputId": "c54f86aa-c398-463d-c17b-532939e105bb"
      },
      "source": [
        "# Downgrade protobuf to a compatible version\n",
        "!pip uninstall protobuf -y\n",
        "!pip install protobuf==3.20.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping protobuf as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "436c4bb4e717453282d7c70a13b4d0ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e8c79edb",
        "outputId": "cd52c2cc-d365-4199-ad44-361b97bc836c"
      },
      "source": [
        "# Uninstall current TensorFlow version\n",
        "!pip uninstall tensorflow -y\n",
        "\n",
        "# Install TensorFlow version 2.15.0\n",
        "!pip install tensorflow==2.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.10.0\n",
            "    Uninstalling keras-3.10.0:\n",
            "      Successfully uninstalled keras-3.10.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "ml_dtypes",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "2d1ca4dcb3a64db6adc775e7b56c7a9d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc7aa69f",
        "outputId": "fbf68e02-3460-4316-8548-71045207ce34"
      },
      "source": [
        "!pip uninstall tensorflow-object-detection-api -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow_object_detection_api 0.1.1\n",
            "Uninstalling tensorflow_object_detection_api-0.1.1:\n",
            "  Successfully uninstalled tensorflow_object_detection_api-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2867fa10",
        "outputId": "d278f171-0423-452e-f861-b67e2d82083b"
      },
      "source": [
        "!pip install tensorflow_io"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_io) (0.37.1)\n",
            "Downloading tensorflow_io-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_io\n",
            "Successfully installed tensorflow_io-0.37.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7c3f3f3",
        "outputId": "17f85577-12ec-49b9-ca39-4c44315ac2e2"
      },
      "source": [
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    }
  ]
}